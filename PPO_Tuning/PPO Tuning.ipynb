{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-21 13:56:28.896556\n",
      "trading_gym 0.8.1\n",
      "ray 0.7.3\n"
     ]
    }
   ],
   "source": [
    "import trading_gym\n",
    "from trading_gym.registry.gaia.v7.env import GAIAPredictorsContinuousV7\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import ray\n",
    "print(datetime.now())\n",
    "print(trading_gym.__name__, trading_gym.__version__)\n",
    "print(ray.__name__, ray.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray.utils.get_system_memory_bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-21 13:56:30,106\tINFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-08-21_13-56-30_105575_129448/logs.\n",
      "2019-08-21 13:56:30,224\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:44130 to respond...\n",
      "2019-08-21 13:56:30,344\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:47704 to respond...\n",
      "2019-08-21 13:56:30,347\tINFO services.py:809 -- Starting Redis shard with 10.0 GB max memory.\n",
      "2019-08-21 13:56:30,377\tINFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-08-21_13-56-30_105575_129448/logs.\n",
      "2019-08-21 13:56:30,379\tWARNING services.py:1301 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.\n",
      "2019-08-21 13:56:30,381\tINFO services.py:1475 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.7.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "from ray import rllib, tune\n",
    "from trading_gym.ray.logger import calculate_tearsheet, CustomLogger\n",
    "from copy import deepcopy\n",
    "# ray.init(num_cpus=8,ignore_reinit_error=True,object_store_memory= 10*100 )\n",
    "ray.init(ignore_reinit_error=True)\n",
    "#          object_store_memory = 50000000)\n",
    "\n",
    "ray.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up the environment configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trading_gym.registry.gaia.v7.env.GAIAPredictorsContinuousV7 at 0x7f598819b978>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_config = dict()\n",
    "env_config['folds'] =  {\n",
    "    'training-set': [datetime.min, datetime(2008, 3, 18)],\n",
    "    'test-set': [datetime(2008, 3, 19), datetime.max],\n",
    "}\n",
    "env = GAIAPredictorsContinuousV7(env_config)\n",
    "env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seting up the PPO agent's configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a 'common config' that sets ray's params\n",
    "# and then default_config, which sets the PPO config \n",
    "config = rllib.agents.ppo.DEFAULT_CONFIG.copy()\n",
    "#  The env is self.explanatory \n",
    "config['env'] = GAIAPredictorsContinuousV7\n",
    "config['callbacks']['on_train_result'] = tune.function(calculate_tearsheet)\n",
    "config['num_workers'] = 6\n",
    "\n",
    "config['gamma'] = 0 # tune.grid_search([0])\n",
    "config['vf_clip_param'] = 0 # tune.grid_search([0.])\n",
    "config['vf_loss_coeff'] = 0 # tune.grid_search([0.])\n",
    "config['lambda'] = 0 # tune.grid_search([0])\n",
    "\n",
    "config['use_gae'] = False #tune.grid_search([False])\n",
    "config['vf_share_layers'] = True #tune.grid_search([False])\n",
    "\n",
    "# If you do use this, have vf_share_layers as True (loss function then combines ) \n",
    "config['use_lstm']: True\n",
    "# Whether to roll out complete epsiodes or truncate them \n",
    "config['batch_mode'] = 'complete_episodes'\n",
    "\n",
    "\n",
    "# Literature suggests having different LR for actor and critic and -3 and -2 \n",
    "config['lr'] = tune.grid_search([1e-5])\n",
    "\n",
    "# Size of batches collected from each worker (number of experiences used for one iteration of SGD)\n",
    "#  Don't think I actually want to use the following. \n",
    "# config['sample_batch_size'] = tune.grid_search([256])\n",
    "\n",
    "# Increase this to maximize the amount of info(no. of experiences(think transition tuples)) we gather before making an update to policy\n",
    "config['train_batch_size'] = tune.grid_search([4000])\n",
    "# Total SGD batch size across all devices\n",
    "config['sgd_minibatch_size'] = 100\n",
    "# Number of SGD iterations in each outer loop \n",
    "config['num_sgd_iter'] = tune.grid_search([8])\n",
    "\n",
    "\n",
    "# Coefficient of entropy regularizer (i.e how much we encourage explorsation)\n",
    "config['entropy_coeff'] = tune.grid_search([1e-5])\n",
    "\n",
    "# Initial coefficient for KL divergence \n",
    "config['kl_coeff'] = tune.grid_search([0.2])\n",
    "# Target value for the KL divergence \n",
    "config['kl_target'] = tune.grid_search([0.01])\n",
    "\n",
    "# PPO clip parameter\n",
    "config['clip_param'] = tune.grid_search([0.8])\n",
    "# config['ignore_worker_failures'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original paper had some param alpha that they multipled both the adam stepsize and the clipping param. Alpha was linearly annealed from 1 to 0 over training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['env_config'] = env_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = tune.Experiment(\n",
    "    name='0.8_100batch',\n",
    "    run=rllib.agents.ppo.PPOTrainer,\n",
    "    stop={\"timesteps_total\": 1000000},\n",
    "    config=deepcopy(config),\n",
    "#     This determines the number of times the grid search is run. s\n",
    "    num_samples=1,\n",
    "    local_dir='logs/kl_exps',\n",
    "    #checkpoint_freq=int(1e4 / config['train_batch_size']),  # checkpoint every 100k iters\n",
    "    checkpoint_at_end=True,\n",
    "    max_failures=0,\n",
    "    loggers=[CustomLogger],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For now, let us use the architecture that Federico has used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.model import Model\n",
    "from ray.rllib.models.misc import normc_initializer, get_activation_fn\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "\n",
    "class MLP(Model):\n",
    "    def _build_layers_v2(self, input_dict: dict, num_outputs: int, config: dict):\n",
    "        import tensorflow.contrib.slim as slim\n",
    "\n",
    "        with tf.name_scope(\"fc_net\"):\n",
    "            last_layer = input_dict['obs']\n",
    "            activation = get_activation_fn(config.get(\"fcnet_activation\"))\n",
    "            for i, size in enumerate(config.get(\"fcnet_hiddens\"), 1):\n",
    "                last_layer = slim.fully_connected(\n",
    "                    inputs=last_layer,\n",
    "                    num_outputs=size,\n",
    "                    weights_initializer=normc_initializer(1.0),\n",
    "                    activation_fn=activation,\n",
    "                    scope=\"fc{}\".format(i),\n",
    "                )\n",
    "#                 We don't need any dropout at this stage\n",
    "#                 last_layer = tf.layers.dropout(\n",
    "#                     inputs=last_layer,\n",
    "#                     rate=config['custom_options'][\"fcnet_dropout_rate\"],\n",
    "#                     training=input_dict['is_training'],\n",
    "#                     name=\"dropout{}\".format(i),\n",
    "#                 )\n",
    "            output = slim.fully_connected(\n",
    "                inputs=last_layer,\n",
    "                num_outputs=num_outputs,\n",
    "                weights_initializer=normc_initializer(0.01),\n",
    "                activation_fn=None,\n",
    "                scope=\"fc_out\",\n",
    "            )\n",
    "            return output, last_layer\n",
    "\n",
    "ModelCatalog.register_custom_model(MLP.__name__, MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.models.misc import conv2d as rllibconv2d\n",
    "# import tensorflow as tf\n",
    "# from tf.nn import conv2d \n",
    "\n",
    "#             Find a way of implementing the activation as an argument \n",
    "#             activation = 'relu' # or tanh or softplus or sigmoid \n",
    "activation = 'relu'\n",
    "\n",
    "class CNN(Model):\n",
    "#      Check that this is the corect way to use kwargs\n",
    "    def _build_layers_v2(self,input_dict:dict, num_outputs: int, config:dict):\n",
    "        import tensorflow.contrib.slim as slim\n",
    "        \n",
    "        with tf.name_scope(\"cnn_net\"):\n",
    "            last_layer = input_dict['obs']\n",
    "\n",
    "            conv_w1 = tf.Variable(tf.truncated_normal([1,3,int(last_layer.shape[3]),2],stddev=0.5),trainable = \"True\")\n",
    "            layer = tf.nn.conv2d(last_layer,filter = conv_w1,padding='VALID',strides= [1,1,1,1])\n",
    "            norm = tf.layers.batch_normalization(layer)\n",
    "            last_layer = tf.nn.relu(norm)\n",
    "            \n",
    "            con_w2 = tf.Variable(tf.truncated_normal([1,int(last_layer.shape[2]),int(last_layer.shape[3]),48],stddev=0.5),trainable = \"True\")\n",
    "            layer = tf.nn.conv2d(last_layer,filter = conv_w2,padding='VALID',strides=[1,1,1,1])\n",
    "            norm = tf.layers.batch_normalization(layer)\n",
    "            last_layer = tf.nn.relu(norm)\n",
    "            \n",
    "            con_w3 = tf.Variable(tf.truncated_normal([1,int(last_layer.shape[2]),48,1],stddev=0.5),trainable = \"True\")\n",
    "            layer = tf.nn.conv2d(last_layer,filter = conv_w3, padding='VALID',strides=[1,1,1,1])\n",
    "            norm = tf.layers.batch_normalization(layer)\n",
    "            last_layer = tf.nn.relu(norm)\n",
    "            \n",
    "            dense_input = last_layer[:,:,0,0]\n",
    "            out_dim = num_outputs\n",
    "#             Dense fully connected\n",
    "            dense_w = tf.Variable(tf.truncated_normal([int(dense_input.shape[1]),out_dim],stddev=0.1,trainable = \"True\"))\n",
    "            dense_b = tf.Variable(tf.constant(0.1,shape[out_dim]), trainable= \"True\")\n",
    "            out = tf.matmul(dense_input,dense_w) + dense_b\n",
    "            \n",
    "            if activation == 'relu':\n",
    "                output = tf.nn.relu(out)\n",
    "            elif activation == 'tanh':\n",
    "                output = tf.nn.tanh(out)\n",
    "            elif activation == 'softplus':\n",
    "                output = tf.nn.softplus(out)\n",
    "            elif activation=='sigmoid':\n",
    "                output = tf.nn.sigmoid(out)\n",
    "            else: \n",
    "                print(\"CNN Build has failed\")\n",
    "                \n",
    "        \n",
    "        return output, out\n",
    "ModelCatalog.register_custom_model(CNN.__name__, CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config['model']['custom_options'] = {'fcnet_dropout_rate': 0.5}\n",
    "config['model']['custom_model'] = MLP.__name__\n",
    "# config['model']['custom_model'] = CNN.__name__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now run the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NTN: Need to work out what tune.suggest does.\n",
    "May need to .add_configurations for the different experiments (with different hyperparamaeters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "object_store_memory\n",
    "redis_max_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-04 14:02:05,549\tINFO tune.py:65 -- Did not find checkpoint file in logs/kl_exps/0.8_100batch.\n",
      "2019-07-04 14:02:05,550\tINFO tune.py:232 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.2/67.5 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:02:12,785\tINFO policy_evaluator.py:311 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:02:12.787201: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:02:13,488\tINFO dynamic_tf_policy.py:265 -- Initializing loss function with dummy input:\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m /home/Nicholas/.venv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning:\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:02:15,519\tINFO policy_evaluator.py:731 -- Built policy map: {'default_policy': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x7f7c93ee9198>}\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:02:15,520\tINFO policy_evaluator.py:732 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f7c93f06e10>}\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:02:15,520\tINFO policy_evaluator.py:343 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f7c93f069b0>}\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:02:15,883\tINFO multi_gpu_optimizer.py:80 -- LocalMultiGPUOptimizer devices ['/cpu:0']\n",
      "\u001b[2m\u001b[36m(pid=15714)\u001b[0m 2019-07-04 14:02:25,548\tINFO policy_evaluator.py:311 -- Creating policy evaluation worker 3 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=15710)\u001b[0m 2019-07-04 14:02:25,624\tINFO policy_evaluator.py:311 -- Creating policy evaluation worker 6 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=15714)\u001b[0m 2019-07-04 14:02:25.664370: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=15710)\u001b[0m 2019-07-04 14:02:25.674036: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=15715)\u001b[0m 2019-07-04 14:02:25,680\tINFO policy_evaluator.py:311 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=15715)\u001b[0m 2019-07-04 14:02:25.741774: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m 2019-07-04 14:02:26,524\tINFO policy_evaluator.py:311 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m 2019-07-04 14:02:26.631026: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=15711)\u001b[0m 2019-07-04 14:02:27,042\tINFO policy_evaluator.py:311 -- Creating policy evaluation worker 5 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=15711)\u001b[0m 2019-07-04 14:02:27.105475: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=15713)\u001b[0m 2019-07-04 14:02:27,082\tINFO policy_evaluator.py:311 -- Creating policy evaluation worker 4 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=15713)\u001b[0m 2019-07-04 14:02:27.123623: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=15714)\u001b[0m /home/Nicholas/.venv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning:\n",
      "\u001b[2m\u001b[36m(pid=15714)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15714)\u001b[0m Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\u001b[2m\u001b[36m(pid=15714)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m 2019-07-04 14:02:27,731\tINFO dynamic_tf_policy.py:265 -- Initializing loss function with dummy input:\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15715)\u001b[0m /home/Nicholas/.venv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning:\n",
      "\u001b[2m\u001b[36m(pid=15715)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15715)\u001b[0m Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\u001b[2m\u001b[36m(pid=15715)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15710)\u001b[0m /home/Nicholas/.venv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning:\n",
      "\u001b[2m\u001b[36m(pid=15710)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15710)\u001b[0m Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\u001b[2m\u001b[36m(pid=15710)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m /home/Nicholas/.venv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning:\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15711)\u001b[0m /home/Nicholas/.venv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning:\n",
      "\u001b[2m\u001b[36m(pid=15711)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15711)\u001b[0m Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\u001b[2m\u001b[36m(pid=15711)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15713)\u001b[0m /home/Nicholas/.venv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning:\n",
      "\u001b[2m\u001b[36m(pid=15713)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15713)\u001b[0m Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\u001b[2m\u001b[36m(pid=15713)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m 2019-07-04 14:02:32,178\tINFO policy_evaluator.py:437 -- Generating sample batch of size 200\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m 2019-07-04 14:02:32,247\tINFO sampler.py:308 -- Raw obs from env: { 0: { 'agent0': np.ndarray((3,), dtype=float64, min=-1.0, max=3.257, mean=1.267)}}\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m 2019-07-04 14:02:32,250\tINFO sampler.py:309 -- Info return from env: {0: {'agent0': None}}\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m 2019-07-04 14:02:32,251\tINFO sampler.py:407 -- Preprocessed obs: np.ndarray((3,), dtype=float64, min=-1.0, max=3.257, mean=1.267)\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m 2019-07-04 14:02:32,251\tINFO sampler.py:411 -- Filtered obs: np.ndarray((3,), dtype=float64, min=-1.0, max=3.257, mean=1.267)\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m 2019-07-04 14:02:32,252\tINFO sampler.py:525 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                                   'info': None,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                                   'obs': np.ndarray((3,), dtype=float64, min=-1.0, max=3.257, mean=1.267),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                                   'prev_action': np.ndarray((2,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                                   'prev_reward': 0.0,\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m 2019-07-04 14:02:32,252\tINFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m 2019-07-04 14:02:32,577\tINFO sampler.py:552 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m { 'default_policy': ( np.ndarray((1, 2), dtype=float32, min=0.107, max=0.893, mean=0.5),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                       { 'action_prob': np.ndarray((1,), dtype=float32, min=1.013, max=1.013, mean=1.013),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'behaviour_logits': np.ndarray((1, 2), dtype=float32, min=-0.002, max=0.013, mean=0.006),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0)})}\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m 2019-07-04 14:02:32,730\tINFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m { 'agent0': { 'data': { 'action_prob': np.ndarray((20,), dtype=float32, min=0.981, max=1.013, mean=0.999),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'actions': np.ndarray((20, 2), dtype=float32, min=0.009, max=0.991, mean=0.5),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'advantages': np.ndarray((20,), dtype=float32, min=-0.003, max=0.006, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'agent_index': np.ndarray((20,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'behaviour_logits': np.ndarray((20, 2), dtype=float32, min=-0.014, max=0.013, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'dones': np.ndarray((20,), dtype=bool, min=0.0, max=1.0, mean=0.05),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'eps_id': np.ndarray((20,), dtype=int64, min=724242333.0, max=724242333.0, mean=724242333.0),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'infos': np.ndarray((20,), dtype=object, head={'time': Timestamp('2005-12-09 00:00:00'), 'nlv': 100.0, 'nr_contracts': np.ndarray((3,), dtype=float64, min=0.0, max=0.269, mean=0.091), 'bid_prices': np.ndarray((3,), dtype=float64, min=1.0, max=2994.39, mean=1109.14), 'ask_prices': np.ndarray((3,), dtype=float64, min=1.0, max=2994.39, mean=1109.14), 'cost_of_spread': np.ndarray((3,), dtype=float64, min=0.0, max=0.0, mean=0.0), 'cost_of_commissions': np.ndarray((3,), dtype=float64, min=0.0, max=0.0, mean=0.0), 'profit_on_idle_cash': 0.0, 'margin': 0, 'weights_target': np.ndarray((3,), dtype=float32, min=0.0, max=0.893, mean=0.333), 'weights_drift': np.ndarray((3,), dtype=float64, min=0.0, max=1.0, mean=0.333), 'weights_diff': np.ndarray((3,), dtype=float64, min=-1.0, max=0.893, mean=-0.0), 'positions_value_diff': np.ndarray((3,), dtype=float64, min=-100.0, max=89.318, mean=-0.0), 'acq_prices': np.ndarray((3,), dtype=float64, min=1.0, max=2994.39, mean=1109.14), 'nr_contracts_diff': np.ndarray((3,), dtype=float64, min=-100.0, max=0.269, mean=-33.242), 'nlv_pre': 100.0}),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'new_obs': np.ndarray((20, 3), dtype=float32, min=-4.9, max=3.026, mean=0.122),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'obs': np.ndarray((20, 3), dtype=float32, min=-4.9, max=3.257, mean=0.182),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'prev_actions': np.ndarray((20, 2), dtype=float32, min=0.0, max=0.991, mean=0.475),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'prev_rewards': np.ndarray((20,), dtype=float32, min=-0.003, max=0.005, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'rewards': np.ndarray((20,), dtype=float32, min=-0.003, max=0.006, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         't': np.ndarray((20,), dtype=int64, min=0.0, max=19.0, mean=9.5),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'unroll_id': np.ndarray((20,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'value_targets': np.ndarray((20,), dtype=float64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m                         'vf_preds': np.ndarray((20,), dtype=float32, min=0.0, max=0.0, mean=0.0)},\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m 2019-07-04 14:02:34,523\tINFO policy_evaluator.py:474 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m { 'data': { 'action_prob': np.ndarray((200,), dtype=float32, min=0.969, max=1.037, mean=1.0),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'actions': np.ndarray((200, 2), dtype=float32, min=0.003, max=0.997, mean=0.5),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'advantages': np.ndarray((200,), dtype=float32, min=-0.02, max=0.019, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'behaviour_logits': np.ndarray((200, 2), dtype=float32, min=-0.014, max=0.013, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'dones': np.ndarray((200,), dtype=bool, min=0.0, max=1.0, mean=0.05),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'eps_id': np.ndarray((200,), dtype=int64, min=362609190.0, max=1772616078.0, mean=926578828.9),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'infos': np.ndarray((200,), dtype=object, head={'time': Timestamp('2005-12-09 00:00:00'), 'nlv': 100.0, 'nr_contracts': np.ndarray((3,), dtype=float64, min=0.0, max=0.269, mean=0.091), 'bid_prices': np.ndarray((3,), dtype=float64, min=1.0, max=2994.39, mean=1109.14), 'ask_prices': np.ndarray((3,), dtype=float64, min=1.0, max=2994.39, mean=1109.14), 'cost_of_spread': np.ndarray((3,), dtype=float64, min=0.0, max=0.0, mean=0.0), 'cost_of_commissions': np.ndarray((3,), dtype=float64, min=0.0, max=0.0, mean=0.0), 'profit_on_idle_cash': 0.0, 'margin': 0, 'weights_target': np.ndarray((3,), dtype=float32, min=0.0, max=0.893, mean=0.333), 'weights_drift': np.ndarray((3,), dtype=float64, min=0.0, max=1.0, mean=0.333), 'weights_diff': np.ndarray((3,), dtype=float64, min=-1.0, max=0.893, mean=-0.0), 'positions_value_diff': np.ndarray((3,), dtype=float64, min=-100.0, max=89.318, mean=-0.0), 'acq_prices': np.ndarray((3,), dtype=float64, min=1.0, max=2994.39, mean=1109.14), 'nr_contracts_diff': np.ndarray((3,), dtype=float64, min=-100.0, max=0.269, mean=-33.242), 'nlv_pre': 100.0}),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'new_obs': np.ndarray((200, 3), dtype=float32, min=-4.9, max=3.478, mean=0.187),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'obs': np.ndarray((200, 3), dtype=float32, min=-7.11, max=4.833, mean=0.152),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'prev_actions': np.ndarray((200, 2), dtype=float32, min=0.0, max=0.994, mean=0.475),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'prev_rewards': np.ndarray((200,), dtype=float32, min=-0.02, max=0.019, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'rewards': np.ndarray((200,), dtype=float32, min=-0.02, max=0.019, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             't': np.ndarray((200,), dtype=int64, min=0.0, max=19.0, mean=9.5),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=9.0, mean=4.5),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'value_targets': np.ndarray((200,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m             'vf_preds': np.ndarray((200,), dtype=float32, min=0.0, max=0.0, mean=0.0)},\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=15717)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:02:38,672\tINFO multi_gpu_impl.py:146 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m { 'inputs': [ np.ndarray((4000, 2), dtype=float32, min=0.0, max=1.0, mean=0.475),\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m               np.ndarray((4000,), dtype=float32, min=-0.034, max=0.023, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m               np.ndarray((4000, 3), dtype=float32, min=-14.063, max=9.568, mean=0.107),\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m               np.ndarray((4000, 2), dtype=float32, min=0.0, max=1.0, mean=0.5),\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m               np.ndarray((4000,), dtype=float32, min=-8.034, max=5.421, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m               np.ndarray((4000, 2), dtype=float32, min=-0.014, max=0.013, mean=0.003),\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m               np.ndarray((4000,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m               np.ndarray((4000,), dtype=float32, min=0.0, max=0.0, mean=0.0)],\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/action:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m                     <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:02:38,672\tINFO multi_gpu_impl.py:191 -- Divided 4000 rollout sequences, each of length 1, among 1 devices.\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:02:41,431\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:02:43,799\tINFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 31.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 13 s, 1 iter, 4000 ts, 0.00164 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:03:05,646\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 31.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 21 s, 2 iter, 8000 ts, 0.00468 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:03:28,767\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 31.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 30 s, 3 iter, 12000 ts, 0.00268 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:03:52,484\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 38 s, 4 iter, 16000 ts, 0.0025 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:04:15,401\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 46 s, 5 iter, 20000 ts, 0.00239 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:04:40,506\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 54 s, 6 iter, 24000 ts, 0.00534 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:05:04,739\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 63 s, 7 iter, 28000 ts, 0.00307 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:05:27,709\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 71 s, 8 iter, 32000 ts, 0.00285 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:05:51,769\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 79 s, 9 iter, 36000 ts, 0.00253 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:06:15,439\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 87 s, 10 iter, 40000 ts, 0.0065 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:06:38,957\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 96 s, 11 iter, 44000 ts, 0.00387 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:07:00,352\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 104 s, 12 iter, 48000 ts, 0.00538 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:07:21,511\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 111 s, 13 iter, 52000 ts, 0.00233 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:07:43,747\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 118 s, 14 iter, 56000 ts, 0.00394 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:08:05,355\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 126 s, 15 iter, 60000 ts, 0.00589 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:08:26,932\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 134 s, 16 iter, 64000 ts, 0.00431 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:08:48,504\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 141 s, 17 iter, 68000 ts, 0.00561 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:09:09,848\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 149 s, 18 iter, 72000 ts, 0.00479 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:09:31,087\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 156 s, 19 iter, 76000 ts, 0.00309 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:09:53,232\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 164 s, 20 iter, 80000 ts, 0.00438 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:10:15,821\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 171 s, 21 iter, 84000 ts, 0.00641 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:10:37,857\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 180 s, 22 iter, 88000 ts, 0.00478 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:10:58,497\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 187 s, 23 iter, 92000 ts, 0.00486 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:11:19,827\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 194 s, 24 iter, 96000 ts, 0.00488 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:11:41,046\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 202 s, 25 iter, 100000 ts, 0.00575 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:12:01,453\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 208 s, 26 iter, 104000 ts, 0.00568 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:12:22,899\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 216 s, 27 iter, 108000 ts, 0.00509 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:12:44,157\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 224 s, 28 iter, 112000 ts, 0.00615 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:13:04,504\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 231 s, 29 iter, 116000 ts, 0.00575 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:13:25,624\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 238 s, 30 iter, 120000 ts, 0.00637 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:13:46,866\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 246 s, 31 iter, 124000 ts, 0.00779 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:14:07,382\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 253 s, 32 iter, 128000 ts, 0.00571 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:14:28,936\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 260 s, 33 iter, 132000 ts, 0.00748 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:14:53,182\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 274 s, 34 iter, 136000 ts, 0.00756 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:15:23,288\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 285 s, 35 iter, 140000 ts, 0.00596 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:15:43,540\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 293 s, 36 iter, 144000 ts, 0.00654 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:16:05,277\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 300 s, 37 iter, 148000 ts, 0.00803 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:16:26,011\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 308 s, 38 iter, 152000 ts, 0.00655 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:16:46,883\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 316 s, 39 iter, 156000 ts, 0.00486 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:17:08,045\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 323 s, 40 iter, 160000 ts, 0.00767 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:17:29,148\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 330 s, 41 iter, 164000 ts, 0.0063 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:17:50,008\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.0/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 338 s, 42 iter, 168000 ts, 0.00556 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:18:10,892\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 345 s, 43 iter, 172000 ts, 0.00912 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:18:32,318\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 353 s, 44 iter, 176000 ts, 0.00781 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:18:53,466\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 361 s, 45 iter, 180000 ts, 0.00724 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:19:14,405\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 368 s, 46 iter, 184000 ts, 0.00854 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:19:35,612\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 375 s, 47 iter, 188000 ts, 0.00701 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:19:55,948\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 383 s, 48 iter, 192000 ts, 0.00619 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:20:17,211\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 390 s, 49 iter, 196000 ts, 0.00737 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:20:39,261\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 398 s, 50 iter, 200000 ts, 0.00709 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:21:00,715\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 406 s, 51 iter, 204000 ts, 0.00762 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:21:21,664\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 413 s, 52 iter, 208000 ts, 0.00681 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:21:44,402\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 421 s, 53 iter, 212000 ts, 0.00683 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:22:06,978\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 429 s, 54 iter, 216000 ts, 0.00544 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:22:28,632\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 438 s, 55 iter, 220000 ts, 0.00903 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:22:50,773\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 445 s, 56 iter, 224000 ts, 0.00709 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:23:13,441\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 453 s, 57 iter, 228000 ts, 0.00854 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:23:35,541\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 461 s, 58 iter, 232000 ts, 0.00759 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:23:57,254\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 469 s, 59 iter, 236000 ts, 0.00776 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:24:19,917\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 476 s, 60 iter, 240000 ts, 0.00508 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:24:42,567\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 484 s, 61 iter, 244000 ts, 0.00964 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:25:04,714\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 492 s, 62 iter, 248000 ts, 0.00755 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:25:26,276\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 499 s, 63 iter, 252000 ts, 0.00712 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:25:50,677\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 508 s, 64 iter, 256000 ts, 0.00931 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:26:13,349\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 516 s, 65 iter, 260000 ts, 0.00795 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:26:34,487\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 523 s, 66 iter, 264000 ts, 0.00603 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:26:56,474\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 531 s, 67 iter, 268000 ts, 0.00764 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:27:17,575\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 538 s, 68 iter, 272000 ts, 0.00859 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:27:38,929\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 546 s, 69 iter, 276000 ts, 0.00857 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:28:00,063\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 553 s, 70 iter, 280000 ts, 0.00702 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:28:21,160\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 560 s, 71 iter, 284000 ts, 0.00715 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:28:42,293\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 568 s, 72 iter, 288000 ts, 0.00945 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:29:03,659\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.1/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 575 s, 73 iter, 292000 ts, 0.00677 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:29:25,714\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 583 s, 74 iter, 296000 ts, 0.00856 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:29:46,219\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 591 s, 75 iter, 300000 ts, 0.00796 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:30:07,339\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 598 s, 76 iter, 304000 ts, 0.00974 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:30:29,396\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 606 s, 77 iter, 308000 ts, 0.00812 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:30:50,390\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 614 s, 78 iter, 312000 ts, 0.00682 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:31:11,561\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 621 s, 79 iter, 316000 ts, 0.00763 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:31:33,286\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 629 s, 80 iter, 320000 ts, 0.00844 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:31:54,836\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 636 s, 81 iter, 324000 ts, 0.00812 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:32:16,146\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 644 s, 82 iter, 328000 ts, 0.00421 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:32:36,883\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 651 s, 83 iter, 332000 ts, 0.00747 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:32:58,638\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 659 s, 84 iter, 336000 ts, 0.00814 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:33:19,966\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 666 s, 85 iter, 340000 ts, 0.00769 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:33:41,278\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 674 s, 86 iter, 344000 ts, 0.00489 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:34:02,808\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 682 s, 87 iter, 348000 ts, 0.00754 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:34:23,899\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 689 s, 88 iter, 352000 ts, 0.007 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:34:45,579\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 697 s, 89 iter, 356000 ts, 0.0081 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:35:08,419\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 706 s, 90 iter, 360000 ts, 0.00701 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:35:30,810\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 714 s, 91 iter, 364000 ts, 0.00794 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:35:53,110\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 721 s, 92 iter, 368000 ts, 0.00523 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:36:15,065\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 729 s, 93 iter, 372000 ts, 0.00905 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:36:37,202\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 736 s, 94 iter, 376000 ts, 0.00788 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:36:58,256\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 744 s, 95 iter, 380000 ts, 0.0059 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:37:19,338\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 752 s, 96 iter, 384000 ts, 0.00726 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:37:41,001\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 759 s, 97 iter, 388000 ts, 0.00451 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:38:01,871\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 767 s, 98 iter, 392000 ts, 0.00839 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:38:22,800\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 774 s, 99 iter, 396000 ts, 0.00738 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:38:45,030\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 782 s, 100 iter, 400000 ts, 0.00693 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:39:06,296\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.2/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 790 s, 101 iter, 404000 ts, 0.00693 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:39:28,571\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-04 14:39:45,157\tWARNING util.py:64 -- The `experiment_checkpoint` operation took 0.10996532440185547 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.3/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 798 s, 102 iter, 408000 ts, 0.00644 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:39:52,744\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.4/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 806 s, 103 iter, 412000 ts, 0.00808 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:40:16,484\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.4/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 814 s, 104 iter, 416000 ts, 0.00722 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:40:38,817\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.4/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 823 s, 105 iter, 420000 ts, 0.005 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:41:02,017\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.4/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 831 s, 106 iter, 424000 ts, 0.00638 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:41:24,691\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.4/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 838 s, 107 iter, 428000 ts, 0.00835 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:41:46,277\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.4/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 846 s, 108 iter, 432000 ts, 0.00723 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:42:08,071\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.4/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 854 s, 109 iter, 436000 ts, 0.00612 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:42:30,458\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 862 s, 110 iter, 440000 ts, 0.00796 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:42:54,613\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.4/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 871 s, 111 iter, 444000 ts, 0.00841 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:43:18,529\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 879 s, 112 iter, 448000 ts, 0.00618 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:43:42,367\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 888 s, 113 iter, 452000 ts, 0.00974 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:44:05,497\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 896 s, 114 iter, 456000 ts, 0.00626 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:44:31,178\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 905 s, 115 iter, 460000 ts, 0.00771 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:44:57,561\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 914 s, 116 iter, 464000 ts, 0.00908 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:45:22,256\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 922 s, 117 iter, 468000 ts, 0.00906 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:45:47,450\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 931 s, 118 iter, 472000 ts, 0.00892 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:46:11,959\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 940 s, 119 iter, 476000 ts, 0.00835 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:46:35,931\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 947 s, 120 iter, 480000 ts, 0.0075 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:46:59,532\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 955 s, 121 iter, 484000 ts, 0.00851 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:47:20,803\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 963 s, 122 iter, 488000 ts, 0.0068 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:47:42,293\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 970 s, 123 iter, 492000 ts, 0.00897 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:48:04,663\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 978 s, 124 iter, 496000 ts, 0.00651 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:48:25,918\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 985 s, 125 iter, 500000 ts, 0.00733 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:48:47,295\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 993 s, 126 iter, 504000 ts, 0.00808 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:49:08,982\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1000 s, 127 iter, 508000 ts, 0.00681 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:49:30,391\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 33.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1008 s, 128 iter, 512000 ts, 0.00903 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:49:52,337\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 31.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1016 s, 129 iter, 516000 ts, 0.00851 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:50:12,179\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1025 s, 130 iter, 520000 ts, 0.00778 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:50:38,904\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.5/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1036 s, 131 iter, 524000 ts, 0.00789 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:51:01,517\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1046 s, 132 iter, 528000 ts, 0.00719 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:51:23,122\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1055 s, 133 iter, 532000 ts, 0.00656 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:51:44,612\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1062 s, 134 iter, 536000 ts, 0.00768 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:52:06,585\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1070 s, 135 iter, 540000 ts, 0.00763 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:52:28,016\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1078 s, 136 iter, 544000 ts, 0.0102 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:52:49,068\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1086 s, 137 iter, 548000 ts, 0.00571 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:53:11,684\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1095 s, 138 iter, 552000 ts, 0.00736 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:53:33,798\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1105 s, 139 iter, 556000 ts, 0.00899 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:53:55,967\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1114 s, 140 iter, 560000 ts, 0.00849 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:54:18,155\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1123 s, 141 iter, 564000 ts, 0.00804 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:54:40,139\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1133 s, 142 iter, 568000 ts, 0.00707 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:55:01,844\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1142 s, 143 iter, 572000 ts, 0.0093 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:55:23,132\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1149 s, 144 iter, 576000 ts, 0.00796 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:55:47,063\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1158 s, 145 iter, 580000 ts, 0.00541 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:56:08,554\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1166 s, 146 iter, 584000 ts, 0.00836 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:56:30,206\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1174 s, 147 iter, 588000 ts, 0.00745 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:56:52,704\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.6/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1182 s, 148 iter, 592000 ts, 0.00754 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:57:14,973\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1191 s, 149 iter, 596000 ts, 0.00787 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:57:36,588\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1201 s, 150 iter, 600000 ts, 0.00631 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:57:59,114\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1210 s, 151 iter, 604000 ts, 0.00561 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:58:22,089\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1219 s, 152 iter, 608000 ts, 0.00829 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:58:45,355\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1229 s, 153 iter, 612000 ts, 0.00515 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:59:07,832\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1239 s, 154 iter, 616000 ts, 0.00683 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:59:30,430\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1248 s, 155 iter, 620000 ts, 0.00773 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 14:59:53,826\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1258 s, 156 iter, 624000 ts, 0.00837 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:00:17,616\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1269 s, 157 iter, 628000 ts, 0.00836 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:00:40,627\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1279 s, 158 iter, 632000 ts, 0.00664 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:01:03,613\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1288 s, 159 iter, 636000 ts, 0.00652 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:01:27,937\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1298 s, 160 iter, 640000 ts, 0.00874 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:01:50,919\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1306 s, 161 iter, 644000 ts, 0.00729 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:02:13,695\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1314 s, 162 iter, 648000 ts, 0.00874 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:02:36,306\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1321 s, 163 iter, 652000 ts, 0.00497 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:02:58,361\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1329 s, 164 iter, 656000 ts, 0.0084 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:03:21,102\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1338 s, 165 iter, 660000 ts, 0.0106 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:03:42,584\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1346 s, 166 iter, 664000 ts, 0.00679 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:04:06,965\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1355 s, 167 iter, 668000 ts, 0.00619 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:04:31,128\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1366 s, 168 iter, 672000 ts, 0.00843 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:04:54,904\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1377 s, 169 iter, 676000 ts, 0.00737 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:05:17,977\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1386 s, 170 iter, 680000 ts, 0.00773 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:05:41,031\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.7/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1393 s, 171 iter, 684000 ts, 0.0069 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:06:04,187\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1401 s, 172 iter, 688000 ts, 0.00594 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:06:26,401\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1410 s, 173 iter, 692000 ts, 0.0074 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:06:48,218\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1417 s, 174 iter, 696000 ts, 0.0084 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:07:11,787\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1426 s, 175 iter, 700000 ts, 0.00872 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:07:34,923\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1435 s, 176 iter, 704000 ts, 0.011 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:07:56,210\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1444 s, 177 iter, 708000 ts, 0.00782 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:08:18,244\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1453 s, 178 iter, 712000 ts, 0.00795 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:08:40,613\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1462 s, 179 iter, 716000 ts, 0.00724 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:09:03,096\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1473 s, 180 iter, 720000 ts, 0.00879 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:09:25,021\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1482 s, 181 iter, 724000 ts, 0.00914 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:09:47,241\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1491 s, 182 iter, 728000 ts, 0.00757 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:10:09,178\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1500 s, 183 iter, 732000 ts, 0.00955 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:10:30,573\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1508 s, 184 iter, 736000 ts, 0.00543 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:10:52,005\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1515 s, 185 iter, 740000 ts, 0.00794 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:11:13,842\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1523 s, 186 iter, 744000 ts, 0.00623 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:11:38,136\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1533 s, 187 iter, 748000 ts, 0.0102 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:11:59,733\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1541 s, 188 iter, 752000 ts, 0.008 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:12:22,446\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1551 s, 189 iter, 756000 ts, 0.00745 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:12:44,768\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1560 s, 190 iter, 760000 ts, 0.00586 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:13:08,005\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1571 s, 191 iter, 764000 ts, 0.00596 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:13:30,964\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1581 s, 192 iter, 768000 ts, 0.00542 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:13:53,878\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1590 s, 193 iter, 772000 ts, 0.00955 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:14:16,524\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1599 s, 194 iter, 776000 ts, 0.0091 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:14:38,823\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1607 s, 195 iter, 780000 ts, 0.00879 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:15:00,893\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1614 s, 196 iter, 784000 ts, 0.00995 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:15:23,615\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1623 s, 197 iter, 788000 ts, 0.00784 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:15:44,592\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1631 s, 198 iter, 792000 ts, 0.00736 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:16:06,246\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1639 s, 199 iter, 796000 ts, 0.00899 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:16:28,941\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1649 s, 200 iter, 800000 ts, 0.00836 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:16:50,974\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1659 s, 201 iter, 804000 ts, 0.00694 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:17:13,937\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1669 s, 202 iter, 808000 ts, 0.0088 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:17:36,461\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1679 s, 203 iter, 812000 ts, 0.00778 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:18:00,800\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1689 s, 204 iter, 816000 ts, 0.00771 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:18:24,804\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1699 s, 205 iter, 820000 ts, 0.00696 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:18:48,372\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1708 s, 206 iter, 824000 ts, 0.00641 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:19:11,431\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1716 s, 207 iter, 828000 ts, 0.00972 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:19:35,446\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1724 s, 208 iter, 832000 ts, 0.00586 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:19:59,149\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1734 s, 209 iter, 836000 ts, 0.0107 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:20:20,871\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1742 s, 210 iter, 840000 ts, 0.00583 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:20:43,702\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1750 s, 211 iter, 844000 ts, 0.0078 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:21:06,429\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1759 s, 212 iter, 848000 ts, 0.00563 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:21:28,761\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1767 s, 213 iter, 852000 ts, 0.00887 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:21:51,014\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1775 s, 214 iter, 856000 ts, 0.00846 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:22:14,435\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1783 s, 215 iter, 860000 ts, 0.00752 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:22:36,842\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1792 s, 216 iter, 864000 ts, 0.00683 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:22:59,707\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1800 s, 217 iter, 868000 ts, 0.00864 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:23:22,598\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1809 s, 218 iter, 872000 ts, 0.00637 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:23:45,223\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1817 s, 219 iter, 876000 ts, 0.00905 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:24:08,175\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 32.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1826 s, 220 iter, 880000 ts, 0.00745 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:24:30,485\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1834 s, 221 iter, 884000 ts, 0.00777 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:24:49,961\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1840 s, 222 iter, 888000 ts, 0.00562 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:25:06,611\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1847 s, 223 iter, 892000 ts, 0.00702 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:25:22,087\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1853 s, 224 iter, 896000 ts, 0.00796 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:25:38,703\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1860 s, 225 iter, 900000 ts, 0.00866 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:25:53,617\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1866 s, 226 iter, 904000 ts, 0.00893 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:26:09,464\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1872 s, 227 iter, 908000 ts, 0.00698 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:26:24,493\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1878 s, 228 iter, 912000 ts, 0.00985 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:26:40,619\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1885 s, 229 iter, 916000 ts, 0.0106 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:26:55,640\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1891 s, 230 iter, 920000 ts, 0.00678 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:27:11,693\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1897 s, 231 iter, 924000 ts, 0.00623 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:27:27,061\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1903 s, 232 iter, 928000 ts, 0.00822 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:27:43,671\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1910 s, 233 iter, 932000 ts, 0.00807 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:27:59,033\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1916 s, 234 iter, 936000 ts, 0.00856 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:28:14,800\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1922 s, 235 iter, 940000 ts, 0.00789 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:28:29,813\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.8/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1928 s, 236 iter, 944000 ts, 0.0109 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:28:45,564\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1934 s, 237 iter, 948000 ts, 0.00666 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:29:00,594\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1940 s, 238 iter, 952000 ts, 0.00796 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:29:16,346\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1946 s, 239 iter, 956000 ts, 0.00833 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:29:31,184\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1952 s, 240 iter, 960000 ts, 0.00906 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:29:47,156\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1959 s, 241 iter, 964000 ts, 0.00894 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:30:02,022\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1964 s, 242 iter, 968000 ts, 0.00679 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:30:17,787\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1971 s, 243 iter, 972000 ts, 0.00742 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:30:32,773\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1977 s, 244 iter, 976000 ts, 0.00797 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:30:48,722\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1983 s, 245 iter, 980000 ts, 0.00987 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:31:03,775\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1989 s, 246 iter, 984000 ts, 0.00766 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:31:19,626\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 1995 s, 247 iter, 988000 ts, 0.00811 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:31:34,383\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 2001 s, 248 iter, 992000 ts, 0.0069 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:31:50,439\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 7/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tRUNNING, [7 CPUs, 0 GPUs], [pid=15712], 2007 s, 249 iter, 996000 ts, 0.00688 rew\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=15712)\u001b[0m 2019-07-04 15:32:05,367\tWARNING ppo.py:131 -- The magnitude of your environment rewards are more than infx the scale of `vf_clip_param`. This means that it will take more than inf iterations for your value function to converge. If this is not intended, consider increasing `vf_clip_param`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-04 15:32:14,855\tINFO ray_trial_executor.py:187 -- Destroying actor for trial PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'TERMINATED': 1})\n",
      "TERMINATED trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tTERMINATED, [7 CPUs, 0 GPUs], [pid=15712], 2013 s, 250 iter, 1000000 ts, 0.00945 rew\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 30.9/67.5 GB\n",
      "Result logdir: logs/kl_exps/0.8_100batch\n",
      "Number of trials: 1 ({'TERMINATED': 1})\n",
      "TERMINATED trials:\n",
      " - PPOTrainer_GAIAPredictorsContinuousV7_0_clip_param=0.8,entropy_coeff=1e-05,kl_coeff=0.2,kl_target=0.01,lr=1e-05,num_sgd_iter=8,train_batch_size=4000:\tTERMINATED, [7 CPUs, 0 GPUs], [pid=15712], 2013 s, 250 iter, 1000000 ts, 0.00945 rew\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trials = tune.run_experiments(\n",
    "    experiments=experiment,\n",
    "    search_alg=tune.suggest.BasicVariantGenerator(),\n",
    "    scheduler=tune.schedulers.FIFOScheduler(),\n",
    "    verbose=1,\n",
    "    reuse_actors=False,\n",
    "    resume=False,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Restore the agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import cloudpickle\n",
    "from ray.utils import binary_to_hex, hex_to_binary\n",
    "\n",
    "\n",
    "def cloudpickleloads(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        try:\n",
    "            return cloudpickle.loads(hex_to_binary(obj[\"value\"]))\n",
    "        except:\n",
    "            for key, value in obj.items():\n",
    "                if isinstance(value, dict):\n",
    "                    if sorted(value) == ['_type', 'value']:\n",
    "                        obj[key] = cloudpickle.loads(hex_to_binary(value[\"value\"]))\n",
    "                    else:\n",
    "                        obj[key] = cloudpickleloads(value)\n",
    "                elif isinstance(value, list):\n",
    "                    for i, item in enumerate(value):\n",
    "                        obj[key][i] = cloudpickleloads(item)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ETF' object has no attribute '_symbol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0c3ba4d6ba05>\u001b[0m in \u001b[0;36mcloudpickleloads\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhex_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'value'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0c3ba4d6ba05>\u001b[0m in \u001b[0;36mcloudpickleloads\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhex_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'value'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0c3ba4d6ba05>\u001b[0m in \u001b[0;36mcloudpickleloads\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhex_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'value'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0c3ba4d6ba05>\u001b[0m in \u001b[0;36mcloudpickleloads\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhex_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'value'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6ac876e5427c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickleloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhex_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_checkpoint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-0c3ba4d6ba05>\u001b[0m in \u001b[0;36mcloudpickleloads\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhex_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                         \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickleloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-0c3ba4d6ba05>\u001b[0m in \u001b[0;36mcloudpickleloads\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhex_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                         \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickleloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-0c3ba4d6ba05>\u001b[0m in \u001b[0;36mcloudpickleloads\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhex_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                         \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickleloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-0c3ba4d6ba05>\u001b[0m in \u001b[0;36mcloudpickleloads\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                         \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhex_to_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                         \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickleloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_new_Index\u001b[0;34m(cls, d)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_new_PeriodIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_new_PeriodIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, levels, codes, sortorder, names, dtype, copy, name, verify_integrity, _set_identity)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_set_identity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_identity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[0;34m(self, codes, levels)\u001b[0m\n\u001b[1;32m    284\u001b[0m                                  \" inconsistent state\" % (i, level_codes.max(),\n\u001b[1;32m    285\u001b[0m                                                           len(level)))\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m                 raise ValueError(\"Level values must be unique: {values} on \"\n\u001b[1;32m    288\u001b[0m                                  \"level {level}\".format(\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mis_unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1661\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mhas\u001b[0m \u001b[0munique\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m         \"\"\"\n\u001b[0;32m-> 1663\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.is_unique.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._do_unique_check\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._ensure_mapping_populated\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._call_map_locations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/trading_gym/contracts/contracts.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \"\"\"Contracts are mapped by this hash number in the Exchange. Therefore,\n\u001b[1;32m     27\u001b[0m         different contracts have to have different hash number.\"\"\"\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AbstractContract'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/trading_gym/contracts/contracts.py\u001b[0m in \u001b[0;36msymbol\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ETF' object has no attribute '_symbol'"
     ]
    }
   ],
   "source": [
    "# 0.8 clip param -- the best run yet. (200 minibatch size)\n",
    "# path = '/home/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/logs/Playground-2folds-tuning/experiment_state-2019-06-23_12-25-51.json'\n",
    "# 1.5 clip param\n",
    "# path = '/home/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/logs/Playground-2folds-tuning/experiment_state-2019-06-23_14-13-39.json'\n",
    "# # 1.0 clip params\n",
    "# path = '/home/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/logs/Playground-2folds-tuning/experiment_state-2019-06-23_16-20-44.json'\n",
    "# # 0.9 clip param\n",
    "# path = '/home/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/logs/Playground-2folds-tuning/experiment_state-2019-06-23_18-04-12.json'\n",
    "\n",
    "\n",
    "# # 0.8 clip param and 8k batches \n",
    "# path = '/home/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/PPO Tuning/logs/0.8clip_8kbatch/experiment_state-2019-07-02_23-46-28.json'\n",
    "\n",
    "# 0.8 clip and 128 minibatch size \n",
    "# path = ' /home/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/PPO Tuning/logs/kl_exps/0.8_rerun/experiment_state-2019-07-04_08-37-47.json'\n",
    "\n",
    "# 0.8 clip and 400 minibatch size \n",
    "path = '/home/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/PPO Tuning/logs/kl_exps/0.8_400batch/experiment_state-2019-07-04_10-03-58.json'\n",
    "\n",
    "with open(path) as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "runner_data = metadata['runner_data']\n",
    "stats = metadata['stats']\n",
    "\n",
    "checkpoint = metadata['checkpoints'][-1]\n",
    "checkpoint = cloudpickleloads(checkpoint)\n",
    "checkpoint_path = cloudpickle.loads(hex_to_binary(checkpoint['_checkpoint'])).value\n",
    "config = checkpoint['config']\n",
    "env_cls = config['env']\n",
    "env_config = config['env_config']\n",
    "path_restore = os.path.join(checkpoint['logdir'], checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = rllib.agents.ppo.PPOTrainer(config, env_cls)\n",
    "agent.restore(path_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "episode = env.sample_episode(\n",
    "    fold='test-set',\n",
    "    policy=agent,\n",
    "    episode_length=None,\n",
    "    benchmark=env._load_benchmark().squeeze(),\n",
    "    risk_free=env._load_risk_free().squeeze(),\n",
    "    burn=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "episode.renderer.plotly_report()\n",
    "tearsheet = episode.renderer.tearsheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tearsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tearsheet.iloc[-1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let us compare the annual turnover for all the different clipping params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {0.5 : '/home/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/logs/Playground-2folds-tuning/experiment_state-2019-06-20_15-53-36.json',\n",
    "         0.7 : '/homve/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/logs/Playground-2folds-tuning/experiment_state-2019-06-23_20-20-56.json', \n",
    "         0.8 : '/home/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/logs/Playground-2folds-tuning/experiment_state-2019-06-23_12-25-51.json', \n",
    "         0.85: '/home/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/logs/Playground-2folds-tuning/experiment_state-2019-06-23_22-00-56.json',\n",
    "         0.9 : '/home/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/logs/Playground-2folds-tuning/experiment_state-2019-06-23_18-04-12.json', \n",
    "         1.0 : '/home/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/logs/Playground-2folds-tuning/experiment_state-2019-06-23_16-20-44.json',\n",
    "         1.5 : '/home/Nicholas/Desktop/trading-gym/notebooks/registry/gaia/v7/logs/Playground-2folds-tuning/experiment_state-2019-06-23_14-13-39.json'}\n",
    "\n",
    "turnovers = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value, path in paths.items():\n",
    "    \n",
    "    with open(path) as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    runner_data = metadata['runner_data']\n",
    "    stats = metadata['stats']\n",
    "\n",
    "    checkpoint = metadata['checkpoints'][-1]\n",
    "    checkpoint = cloudpickleloads(checkpoint)\n",
    "    # print(checkpoint)\n",
    "    checkpoint_path = cloudpickle.loads(hex_to_binary(checkpoint['_checkpoint'])).value\n",
    "#     print(checkpoint_path)\n",
    "    config = checkpoint['config']\n",
    "    env_cls = config['env']\n",
    "    env_config = config['env_config']\n",
    "    path_restore = os.path.join(checkpoint['logdir'], checkpoint_path)\n",
    "    \n",
    "    agent = rllib.agents.ppo.PPOTrainer(config, env_cls)\n",
    "    agent.restore(path_restore)\n",
    "    \n",
    "    episode = env.sample_episode(\n",
    "    fold='test-set',\n",
    "    policy=agent,\n",
    "    episode_length=None,\n",
    "    benchmark=env._load_benchmark().squeeze(),\n",
    "    risk_free=env._load_risk_free().squeeze(),\n",
    "    burn=1,\n",
    "    )\n",
    "    \n",
    "    tearsheet = episode.renderer.tearsheet()\n",
    "    \n",
    "    turnover -= tearsheet.iloc[-1,0]\n",
    "    turnovers[value] = turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
